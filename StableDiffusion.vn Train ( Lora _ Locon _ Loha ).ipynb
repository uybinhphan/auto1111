{"cells":[{"cell_type":"markdown","metadata":{"id":"QCPFkm6hfjnm"},"source":["# [![](https://img.shields.io/badge/Thi·∫øt%20k·∫ø-stablediffusion.vn-0075ff)](https://stablediffusion.vn) [![](https://img.shields.io/badge/Phi√™n%20b·∫£n-v1.5-0075ff)](https://stablediffusion.vn) [![](https://img.shields.io/badge/Group-Support-0075ff)](https://www.facebook.com/groups/stablediffusion.vn) [![](https://img.shields.io/badge/B·ªô%20c√¥ng%20c·ª•-ƒê·∫ßy%20ƒë·ªß-0075ff)](https://stablediffusion.vn/bo-cong-cu/) [![](https://img.shields.io/discord/813085864355037235?color=blue&label=Discord&logo=Discord)](https://discord.gg/5SEtApPeyG) [![](https://img.shields.io/badge/Donate-SDVN-green)](https://stablediffusion.vn/donate/) \n","\n","---\n","# üí° H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng :\n"," \n"," \n"," - B1 : Chu·∫©n b·ªã th∆∞ m·ª•c ·∫£nh m·∫´u ƒë·ªÉ train theo ƒë√∫ng k√≠ch th∆∞·ªõc (ex:512x512 , 768x768), t·∫£i l√™n drive\n"," - B1 : Ch·∫°y ph·∫ßn 1\n"," - B2 : Ch·ªânh Path ƒë·ªÉ d·∫´n ƒë·∫øn th∆∞ m·ª•c data ƒë√£ t·∫£i v√† ch·∫°y ph·∫ßn 2\n"," - B3 : Ch·ªânh c√°c th√¥ng s·ªë train t·∫°i m·ª•c 3 v√† ch·∫°y ph·∫ßn 3\n"," - B4 : Ch·∫°y m·ª•c 4 v√† theo d√µi k·∫øt qu·∫£ train\n"," ---\n","\n"," üîª : L∆∞u √Ω quan tr·ªçng thay ƒë·ªïi theo m·ªói l·∫ßn train\n","\n"," üî∏ : Gi√° tr·ªã tham kh·∫£o, c√≥ th·ªÉ ƒë·ªÉ m·∫∑c ƒë·ªãnh\n","\n"," üîπ : Gi√° tr·ªã n√™n ƒë·ªÉ m·∫∑c ƒë·ªãnh\n","\n"," *C√°c gi√° tr·ªã m·∫∑c ƒë·ªãnh ƒë∆∞·ª£c t·ªëi ∆∞u cho ·∫£nh train m·∫´u ng∆∞·ªùi v·ªõi 10 ·∫£nh, c√°c th∆∞ m·ª•c m·∫∑c ƒë·ªãnh ƒë∆∞·ª£c t·ªëi ∆∞u cho drive s·ª≠  d·ª•ng SD-WebUI tr√™n stablediffusion.vn*\n"]},{"cell_type":"markdown","metadata":{"id":"IPT0DeMD761Z"},"source":["# üîå 1. C√†i ƒë·∫∑t n·ªÅn"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"OKPLNy721RWN"},"outputs":[],"source":["#@title\n","\n","#Dreamboot Lora by stablediffusion.vn - hungdiffusion - 24/03/2023\n","#Lora Dreamboot origin - kohya\n","\n","import os\n","import zipfile\n","import shutil\n","from subprocess import getoutput\n","from IPython.utils import capture\n","from google.colab import drive\n","%store -r\n","\n","!nvidia-smi\n","!pip install -q torch==2.0.0+cu118 torchvision==0.15.1+cu118 torchaudio==2.0.1+cu118 torchtext==0.15.1 torchdata==0.6.0 --extra-index-url https://download.pytorch.org/whl/cu118 -U\n","!pip install -q xformers==0.0.19 triton==2.0.0 -U\n","\n","\n","#root_dir\n","root_dir = \"/content\"\n","deps_dir = os.path.join(root_dir,\"deps\")\n","repo_dir = os.path.join(root_dir,\"kohya-trainer\")\n","training_dir = os.path.join(root_dir,\"LoRA\")\n","pretrained_model = os.path.join(root_dir,\"pretrained_model\")\n","vae_dir = os.path.join(root_dir,\"vae\")\n","config_dir = os.path.join(training_dir,\"config\")\n","\n","#repo_dir\n","accelerate_config = os.path.join(repo_dir, \"accelerate_config/config.yaml\")\n","tools_dir = os.path.join(repo_dir,\"tools\")\n","finetune_dir = os.path.join(repo_dir,\"finetune\")\n","\n","for store in [\"root_dir\", \"deps_dir\", \"repo_dir\", \"training_dir\", \"pretrained_model\", \"vae_dir\", \"accelerate_config\", \"tools_dir\", \"finetune_dir\", \"config_dir\"]:\n","  with capture.capture_output() as cap:\n","    %store {store}\n","    del cap\n","\n","repo_url = \"https://github.com/phamhungd/kohya-trainer\"\n","branch = \"\" \n","install_xformers = True \n","mount_drive = True\n","\n","if mount_drive:\n","  if not os.path.exists('/content/drive'):\n","    drive.mount('/content/drive')\n","\n","for dir in [deps_dir, training_dir, config_dir, pretrained_model, vae_dir]:\n","  os.makedirs(dir, exist_ok=True)\n","  \n","def clone_repo(url):\n","  if not os.path.exists(repo_dir):\n","    os.chdir(root_dir)\n","    !git clone {url} {repo_dir}\n","  else:\n","    os.chdir(repo_dir)\n","    !git pull origin {branch} if branch else !git pull\n","\n","clone_repo(repo_url)\n","\n","if branch:\n","  os.chdir(repo_dir)\n","  status = os.system(f\"git checkout {branch}\")\n","  if status != 0:\n","    raise Exception(\"Failed to checkout branch or commit\")\n","\n","os.chdir(repo_dir)\n","\n","def ubuntu_deps(url, name, dst):\n","  with capture.capture_output() as cap:\n","    !wget -q --show-progress {url}\n","    with zipfile.ZipFile(name, 'r') as deps:\n","      deps.extractall(dst)\n","    !dpkg -i {dst}/*\n","    os.remove(name)\n","    shutil.rmtree(dst)\n","    del cap \n","\n","def install_dependencies():\n","  !pip -q install --upgrade -r requirements.txt\n","\n","  if install_xformers:\n","    !pip install xformers triton\n","\n","  from accelerate.utils import write_basic_config\n","  if not os.path.exists(accelerate_config):\n","    write_basic_config(save_location=accelerate_config)\n","\n","os.chdir(repo_dir)\n","ubuntu_deps(\"https://huggingface.co/Linaqruf/fast-repo/resolve/main/deb-libs.zip\", \"deb-libs.zip\", deps_dir)\n","install_dependencies()"]},{"cell_type":"markdown","metadata":{"id":"K8uu_uAj8GUw"},"source":["# üìÇ 2. K·∫øt n·ªëi data Train"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"Ccsl1_k31mtP"},"outputs":[],"source":["\n","#@markdown ##<br>üîª 2.1 ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c d·ªØ li·ªáu trong drive \n","#@markdown <br>\n","import os\n","from IPython.utils import capture\n","import random\n","import concurrent.futures\n","from tqdm import tqdm\n","from PIL import Image\n","%store -r\n","\n","\n","Train_Data_Path = \"/content/drive/MyDrive/SD-Data/TrainData/\" #@param {type:'string'}\n","#@markdown <br> ‚úÖ  --- *`T·ªáp h·ªó tr·ª£ : \".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\"`*\n","#@markdown <br> ‚ùå  --- *`T·ªáp kh√¥ng h·ªó tr·ª£ : \".PNG\", \".JPG\", \".JPEG\", \".WEBP\", \".BMP\"`*\n","train_data_dir = Train_Data_Path\n","reg_data_dir = train_data_dir\n","\n","for image_dir in [train_data_dir, reg_data_dir]:\n","  if image_dir:\n","    with capture.capture_output() as cap:\n","      os.makedirs(image_dir, exist_ok=True)\n","      %store image_dir\n","      del cap\n","\n","print(f\"Your train data directory : {train_data_dir}\")\n","\n","os.chdir(root_dir)\n","\n","test = os.listdir(train_data_dir)\n","os.chdir(finetune_dir)\n","#@markdown <br> B·ªè ch·ªçn delete_metadata n·∫øu kh√¥ng mu·ªën t·ª± t·∫°o tag ·ªü m·ª•c 2.2 :\n","#@markdown <br>\n","delete_metadata = False # @param {type: \"boolean\"}\n","\n","if not delete_metadata:\n","  supported_types = [\".png\", \".jpg\", \".jpeg\", \".PNG\", \".JPG\", \".JPEG\", \".webp\", \".bmp\", \".caption\", \".npz\", \".txt\", \".json\"]\n","else:\n","  supported_types = [\".png\", \".jpg\", \".jpeg\", \".PNG\", \".JPG\", \".JPEG\", \".webp\", \".bmp\"]\n","\n","for item in test:\n","    file_ext = os.path.splitext(item)[1]\n","    if file_ext not in supported_types:\n","        print(f\"Deleting file {item} from {train_data_dir}\")\n","        os.remove(os.path.join(train_data_dir, item))\n","\n","#@markdown ##<br>üî∏ 2.2 T·∫°o tag m√¥ t·∫£ cho ·∫£nh (Waifu Diffusion 1.4 Tagger V2) :\n","#@markdown <br> Ch·ªânh threshold th·∫•p (0.35) ƒë·ªëi v·ªõi train style, khung c·∫£nh , ch·ªânh threshold cao (0.85) ƒë·ªëi v·ªõi train nh√¢n v·∫≠t, ƒë·ªëi t∆∞·ª£ng, ch·ªânh 1 ƒë·ªÉ kh√¥ng t·ª± t·∫°o tag :\n","#@markdown <br>\n","\n","batch_size = 8 \n","max_data_loader_n_workers = 2 \n","model = \"SmilingWolf/wd-v1-4-swinv2-tagger-v2\"\n","threshold = 0.85 #@param {type:\"slider\", min:0, max:1, step:0.05}\n","if delete_metadata == True :\n"," !python tag_images_by_wd14_tagger.py \\\n","  \"{train_data_dir}\" \\\n","  --batch_size {batch_size} \\\n","  --repo_id {model} \\\n","  --thresh {threshold} \\\n","  --caption_extension .txt \\\n","  --max_data_loader_n_workers {max_data_loader_n_workers}\n","\n","#@markdown N·ªëi th√™m tag tu·ª≥ ch·ªçn v√†o ƒë·∫ßu txt :\n","extension = \".txt\"\n","custom_tag = \"\" #@param {type:\"string\"}\n","#@markdown T√≠ch ch·ªçn append ƒë·ªÉ customtag xu·∫•t hi·ªán ·ªü cu·ªëi m√¥ t·∫£ :\n","append = False #@param {type:\"boolean\"}\n","if extension != \"\" :\n"," def add_tag(filename, tag, append):\n","    with open(filename, \"r\") as f:\n","        contents = f.read()\n","        \t    \t\n","    tag = \", \".join(tag.split())\n","    tag = tag.replace(\"_\", \" \")\n","    \n","    if tag in contents:\n","        return\n","\n","    if append:\n","      contents = contents.rstrip() + \", \" + tag\n","    else:\n","      contents = tag + \", \" + contents\n","    \n","    with open(filename, \"w\") as f:\n","        f.write(contents)\n","\n"," if not any([filename.endswith(\".\" + extension) for filename in os.listdir(train_data_dir)]):\n","    for filename in os.listdir(train_data_dir):\n","        if filename.endswith((\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")):\n","            open(os.path.join(train_data_dir, filename.split(\".\")[0] + \".\" + extension), \"w\").close()\n","\n"," tags = custom_tag.split()\n","\n"," if custom_tag:\n","  for filename in os.listdir(train_data_dir):\n","      if filename.endswith(extension):\n","          for tag in tags:\n","              add_tag(os.path.join(train_data_dir, filename), tag, append)"]},{"cell_type":"markdown","metadata":{"id":"FjyVzjZp4E02"},"source":["# ‚öôÔ∏è 3. C√†i ƒë·∫∑t Train"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"vO6SNKg03yhN"},"outputs":[],"source":["from google.colab import drive\n","#@markdown ##<br>üîª 3.1 C√†i ƒë·∫∑t Lora :\n","#@markdown <br>\n","v_parameterization = False\n","Lora_name = \"\" #@param {type:\"string\"}\n","project_name = Lora_name\n","if not project_name:\n","  project_name = \"Loratrain\"\n","#@markdown <br>*ƒê·ªÉ tr·ªëng model train ƒë·ªÉ k√≠ch ho·∫°t custom model* \n","#ModelTrain\n","modelDown = [\"\",\n","             \"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/cag/anything-v3-1/resolve/main/anything-v3-1.safetensors -d /content/model -o AnythingV3.safetensors\",\n","             \"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/chillout_mix-pruned.safetensors -d /content/model -o Chilloutmix.safetensors\",\n","             \"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Linaqruf/stolen/resolve/main/pruned-models/stable_diffusion_1_5-pruned.safetensors -d /content/model -o StableDiffusionV15.safetensors\",\n","             \"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors -d /content/model -o v2-StableDiffusionV21-512.safetensors\",\n","             \"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors -d /content/model -o v2-StableDiffusionV21-768.safetensors\",\n","             \"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e2.ckpt -d /content/model -o v2-WaijuDiffusionV14.safetensors\",]\n","\n","vaeDown = [\"\",\n","           \"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/phamhungd/GuoZovya/resolve/main/Anime.ckpt -d /content/VAE -o Animevae.vae.pt\",\n","           \"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime.ckpt -d /content/VAE -o Kl-f8-anime.vae.pt\",\n","           \"aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt -d /content/VAE -o VAE84EMA.vae.pt\",]\n","modelPath = [\"\",\n","            \"/content/model/AnythingV3.safetensors\",\n","            \"/content/model/Chilloutmix.safetensors\",\n","            \"/content/model/StableDiffusionV15.safetensors\",\n","            \"/content/model/v2-StableDiffusionV21-512.safetensors\",\n","            \"/content/model/v2-StableDiffusionV21-768.safetensors\",\n","            \"/content/model/v2-WaijuDiffusionV14.safetensors\",]\n","modelList = [\"\",\n","             \"AnythingV3\",\n","             \"Chilloutmix\",\n","             \"StableDiffusionV15\",\n","             \"v2-StableDiffusionV21-512\",\n","             \"v2-StableDiffusionV21-768\",\n","             \"v2-WaijuDiffusionV14\",]\n","\n","Model_Train_Name = \"Chilloutmix\"  #@param [\"\", \"AnythingV3\", \"Chilloutmix\", \"StableDiffusionV15\", \"v2-StableDiffusionV21-512\", \"v2-StableDiffusionV21-768\", \"v2-WaijuDiffusionV14\"]\n","Custom_Model_Path = \"\" #@param {type:\"string\"}\n","v2 = False #@param {type:\"boolean\"}\n","\n","if Model_Train_Name != \"\":\n","  !{modelDown[modelList.index(Model_Train_Name)]}\n","  pretrained_model_name_or_path=modelPath[modelList.index(Model_Train_Name)]\n","else:\n","  pretrained_model_name_or_path=Custom_Model_Path\n","#@markdown <br>*ƒê·ªÉ tr·ªëng VAE ƒë·ªÉ kh√¥ng k√≠ch ho·∫°t VAE* \n","vaePath = [ \"\",\n","            \"/content/VAE/Animevae.vae.pt\",\n","            \"/content/VAE/Kl-f8-anime.vae.pt\",\n","            \"/content/VAE/VAE84EMA.vae.pt\",]\n","vaeList = [\"\",\n","           \"Animevae\",\n","           \"Kl-f8-anime\",\n","           \"VAE84EMA\",]\n","VAE = \"VAE84EMA\"  #@param [\"\", \"Animevae\", \"Kl-f8-anime\", \"VAE84EMA\"]\n","!{vaeDown[vaeList.index(VAE)]}\n","vae = vaePath[vaeList.index(VAE)]\n","Output_Path = \"/content/drive/MyDrive/SD-Data/Lora/\" #@param {'type':'string'}\n","output_dir = Output_Path\n","output_to_drive = False\n","print(\"Project Name: \", project_name)\n","print(\"Model Version: Stable Diffusion V1.x\") if not v2 else \"\"\n","print(\"Model Version: Stable Diffusion V2.x\") if v2 and not v_parameterization else \"\"\n","print(\"Model Version: Stable Diffusion V2.x 768v\") if v2 and v_parameterization else \"\"\n","print(\"Pretrained Model Path: \", pretrained_model_name_or_path) if pretrained_model_name_or_path else print(\"No Pretrained Model path specified.\")\n","print(\"VAE Path: \", vae) if vae else print(\"No VAE path specified.\")\n","print(\"Output Path: \", output_dir)\n","\n","import toml\n","#@markdown ##<br>üîª 3.2 C·∫•u h√¨nh Dreambooth :\n","#@markdown ##<br>\n","#@markdown  *S·ªë l∆∞·ª£t l·∫∑p l·∫°i ·∫£nh trong th∆∞ m·ª•c :*\n","train_repeats = 48 #@param {type:\"number\"}\n","reg_repeats = 1 \n","instance_token = \"mksks\" \n","class_token = \"style\"\n","#@markdown  *K√≠ch th∆∞·ªõc ·∫£nh train (px) :*\n","resolution = 512 # @param {type:\"slider\", min:512, max:1024, step:128}\n","#@markdown <br>*C√†i ƒë·∫∑t s·ªë ·∫£nh x·ª≠ l√Ω trong 1 step:*\n","#@markdown <br>```resolution = 512 => b= 6```\n","#@markdown <br>```resolution = 768 => b= 4```\n","#@markdown <br>```resolution = 896 => b= 2```\n","#@markdown <br>```resolution = 1024 => b= 1```\n","Batch_size = 6 #@param {type:\"number\"}\n","flip_aug = False \n","caption_extension = \".txt\" \n","caption_dropout_rate = 0 \n","caption_dropout_every_n_epochs = 0 \n","keep_tokens = 0 \n","\n","config = {\n","    \"general\": {\n","        \"enable_bucket\": True,\n","        \"caption_extension\": caption_extension,\n","        \"shuffle_caption\": True,\n","        \"keep_tokens\": keep_tokens,\n","        \"bucket_reso_steps\": 64,\n","        \"bucket_no_upscale\": False,\n","    },\n","    \"datasets\": [\n","        {\n","            \"resolution\": resolution,\n","            \"min_bucket_reso\": 320 if resolution > 640 else 256,\n","            \"max_bucket_reso\": 1280 if resolution > 640 else 1024,           \n","            \"caption_dropout_rate\": caption_dropout_rate if caption_extension == \".caption\" else 0,\n","            \"caption_tag_dropout_rate\": caption_dropout_rate if caption_extension == \".txt\" else 0,\n","            \"caption_dropout_every_n_epochs\": caption_dropout_every_n_epochs,\n","            \"flip_aug\": flip_aug,\n","            \"color_aug\": False,\n","            \"face_crop_aug_range\": None,\n","            \"subsets\": [\n","                {\n","                    \"image_dir\": train_data_dir,\n","                    \"class_tokens\": f\"{instance_token} {class_token}\",\n","                    \"num_repeats\": train_repeats,\n","                },\n","                {\n","                    \"is_reg\": True,\n","                    \"image_dir\": reg_data_dir,\n","                    \"class_tokens\": class_token,\n","                    \"num_repeats\": reg_repeats,\n","                }\n","            ]\n","        }\n","    ]\n","}\n","\n","config_str = toml.dumps(config)\n","\n","dataset_config = os.path.join(config_dir, \"dataset_config.toml\")\n","\n","for key in config:\n","    if isinstance(config[key], dict):\n","        for sub_key in config[key]:\n","            if config[key][sub_key] == \"\":\n","                config[key][sub_key] = None\n","    elif config[key] == \"\":\n","        config[key] = None\n","\n","config_str = toml.dumps(config)\n","\n","with open(dataset_config, \"w\") as f:\n","    f.write(config_str)\n","\n","print(config_str)\n","\n","#@markdown ##<br>üî∏ 3.3 C√†i ƒë·∫∑t ·∫£nh m·∫´u :\n","enable_sample = True\n","sample_every_n_type = \"sample_every_n_epochs\"\n","#@markdown <br>*L∆∞u m·∫´u th·ª≠ sau m·ªói n v√≤ng l·∫•y m·∫´u*\n","sample_every_n_type_value = 2 #@param {type:\"number\"}\n","if not enable_sample:\n","  sample_every_n_type_value = 999999\n","sampler = \"euler_a\"\n","#@markdown *Prompt m√¥ t·∫£ ·∫£nh m·∫´u*\n","prompt = \"1girl in the beach, masterpiece,ultra realistic,32k,extremely detailed CG unity 8k wallpaper, best quality\" #@param {type: \"string\"}\n","negative = \"watermark,text, logo,contact, error, blurry, cropped, username, artist name, (worst quality, low quality:1.4),\"\n","width = 512\n","height = 768 #@param {type:\"number\"}\n","scale = 7 \n","seed = -1 \n","steps = 20 \n","\n","sample_str = f\"\"\"\n","  {prompt} \\\n","  --n {negative} \\\n","  --w {width} \\\n","  --h {height} \\\n","  --l {scale} \\\n","  --s {steps} \\\n","  {f\"--d \" + seed if seed > 0 else \"\"} \\\n","\"\"\"\n","\n","prompt_path = os.path.join(config_dir, \"sample_prompt.txt\")\n","\n","with open(prompt_path, \"w\") as f:\n","    f.write(sample_str)\n","\n","#@markdown ###<br>üî∏ 3.4 Setting Dim - Alpha ( 16 - 128)\n","#@markdown <br>\n","network_category = \"LoRA\"  # @param [\"LoRA\", \"LoCon\", \"LoCon_Lycoris\", \"LoHa\"]\n","\n","# @markdown C√†i ƒë·∫∑t ch·ªâ s·ªë t∆∞∆°ng ·ª©ng:\n","\n","# @markdown | network_category | conv_dim | conv_alpha |network_dim | network_alpha | \n","# @markdown | :---: | :---: | :---: | :---: | :---: |\n","# @markdown | LoRA | - | - | 32 | 1 |\n","# @markdown | LoCon | 8 | 1 | 16 | 8 |\n","# @markdown | LoHa | 4 | 1 | 8 | 4 |\n","# @markdown `conv_dim` v√† `conv_alpha` c·∫ßn c√≥ khi ƒë√†o t·∫°o `LoCon` and `LoHa`, b·ªè qua n√≥ khi ƒë√†o t·∫°o l√† `LoRA`. Tuy nhi√™n, n·∫øu l·ªói n√™n ƒë·∫∑t `dim = alpha`.\n","conv_dim = 1  # @param {'type':'number'}\n","conv_alpha = 1  # @param {'type':'number'}\n","\n","network_dim = 32 #@param {'type':'number'}\n","network_alpha = 32 #@param {'type':'number'}\n","network_weight = \"\"\n","network_module = \"lycoris.kohya\" if network_category in [\"LoHa\", \"LoCon_Lycoris\"] else \"networks.lora\"\n","network_args = \"\" if network_category == \"LoRA\" else [\n","    f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\",\n","    ]\n","\n","if network_category == \"LoHa\":\n","  network_args.append(\"algo=loha\")\n","elif network_category == \"LoCon_Lycoris\":\n","  network_args.append(\"algo=lora\")\n","#@markdown ### <br>üîπ 3.5 Optimizer Config:\n","#@markdown <br>\n","optimizer_type = \"AdamW8bit\" #@param [\"AdamW\", \"AdamW8bit\", \"Lion\", \"SGDNesterov\", \"SGDNesterov8bit\", \"DAdaptation\", \"AdaFactor\"]\n","optimizer_args = \"\" \n","train_unet = True\n","#@markdown ### <br>üî∏ 3.6 Learning rate:\n","#@markdown <br>*N√™n ƒë·∫∑t unet_lr = 2 x text_encoder_lr*\n","unet_lr = 1e-4 #@param {'type':'number'}\n","train_text_encoder = True\n","text_encoder_lr = 5e-5 #@param {'type':'number'}\n","lr_scheduler = \"constant\" #@param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\", \"adafactor\"] {allow-input: false}\n","lr_warmup_steps = 0 \n","lr_scheduler_num_cycles = 0 \n","lr_scheduler_power = 0\n","\n","print(\"- LoRA Config:\")\n","print(f\"  - Additional network category: {network_category}\")\n","print(f\"  - Loading network module: {network_module}\")\n","if not network_category == \"LoRA\":\n","  print(f\"  - network args: {network_args}\")\n","print(f\"  - {network_module} linear_dim set to: {network_dim}\")\n","print(f\"  - {network_module} linear_alpha set to: {network_alpha}\")\n","if not network_category == \"LoRA\":\n","  print(f\"  - {network_module} conv_dim set to: {conv_dim}\")\n","  print(f\"  - {network_module} conv_alpha set to: {conv_alpha}\")\n","\n","if not network_weight:\n","    print(\"  - No LoRA weight loaded.\")\n","else:\n","    if os.path.exists(network_weight):\n","        print(f\"  - Loading LoRA weight: {network_weight}\")\n","    else:\n","        print(f\"  - {network_weight} does not exist.\")\n","        network_weight = \"\"\n","\n","print(\"- Optimizer Config:\")\n","print(f\"  - Using {optimizer_type} as Optimizer\")\n","if optimizer_args:\n","    print(f\"  - Optimizer Args: {optimizer_args}\")\n","if train_unet and train_text_encoder:\n","    print(\"  - Train UNet and Text Encoder\")\n","    print(f\"    - UNet learning rate: {unet_lr}\")\n","    print(f\"    - Text encoder learning rate: {text_encoder_lr}\")\n","if train_unet and not train_text_encoder:\n","    print(\"  - Train UNet only\")\n","    print(f\"    - UNet learning rate: {unet_lr}\")\n","if train_text_encoder and not train_unet:\n","    print(\"  - Train Text Encoder only\")\n","    print(f\"    - Text encoder learning rate: {text_encoder_lr}\")\n","print(f\"  - Learning rate warmup steps: {lr_warmup_steps}\")\n","print(f\"  - Learning rate Scheduler: {lr_scheduler}\")\n","if lr_scheduler == \"cosine_with_restarts\":\n","    print(f\"  - lr_scheduler_num_cycles: {lr_scheduler_num_cycles}\")\n","elif lr_scheduler == \"polynomial\":\n","    print(f\"  - lr_scheduler_power: {lr_scheduler_power}\")\n","\n","#@markdown ##<br>üîª 3.7 Training config\n","\n","import toml\n","import os\n","%store -r\n","\n","lowram = True \n","noise_offset = 0.0\n","#@markdown <br>*C√†i ƒë·∫∑t s·ªë v√≤ng l·∫•y m·∫´u*\n","\n","num_epochs = 12 #@param {type:\"number\"}\n","\n","train_batch_size = Batch_size\n","mixed_precision = \"fp16\" \n","save_precision = \"fp16\" \n","save_n_epochs_type = \"save_every_n_epochs\"\n","#@markdown <br>*C√†i ƒë·∫∑t sao l∆∞u k·∫øt qu·∫£ sau m·ªói n v√≤ng l·∫´y m·∫´u:*\n","\n","save_n_epochs_type_value = 2 #@param {type:\"number\"}\n","\n","save_model_as = \"safetensors\" \n","max_token_length = 225\n","clip_skip = 1\n","gradient_checkpointing = False \n","gradient_accumulation_steps = 1 \n","seed = -1\n","logging_dir = \"/content/LoRA/logs\"\n","prior_loss_weight = 1.0\n","              \n","os.chdir(repo_dir)\n","\n","config = {\n","    \"model_arguments\": {\n","        \"v2\": v2,\n","        \"v_parameterization\": v_parameterization if v2 and v_parameterization else False,\n","        \"pretrained_model_name_or_path\": pretrained_model_name_or_path,\n","        \"vae\": vae,\n","    },\n","    \"additional_network_arguments\": {\n","        \"no_metadata\": False,\n","        \"unet_lr\": float(unet_lr) if train_unet else None,\n","        \"text_encoder_lr\": float(text_encoder_lr) if train_text_encoder else None,\n","        \"network_weights\": network_weight,\n","        \"network_module\": network_module,\n","        \"network_dim\": network_dim,\n","        \"network_alpha\": network_alpha,\n","        \"network_args\": network_args,\n","        \"network_train_unet_only\": True if train_unet and not train_text_encoder else False,\n","        \"network_train_text_encoder_only\": True if train_text_encoder and not train_unet else False,\n","        \"training_comment\": None,\n","    },\n","    \"optimizer_arguments\": {\n","        \"optimizer_type\": optimizer_type,\n","        \"learning_rate\": unet_lr,\n","        \"max_grad_norm\": 1.0,\n","        \"optimizer_args\": eval(optimizer_args) if optimizer_args else None,\n","        \"lr_scheduler\": lr_scheduler,\n","        \"lr_warmup_steps\": lr_warmup_steps,\n","        \"lr_scheduler_num_cycles\": lr_scheduler_num_cycles if lr_scheduler == \"cosine_with_restarts\" else None,\n","        \"lr_scheduler_power\": lr_scheduler_power if lr_scheduler == \"polynomial\" else None,\n","    },\n","    \"dataset_arguments\": {\n","        \"cache_latents\": True,\n","        \"debug_dataset\": False,\n","    },\n","    \"training_arguments\": {\n","        \"output_dir\": output_dir,\n","        \"output_name\": project_name,\n","        \"save_precision\": save_precision,\n","        \"save_every_n_epochs\": save_n_epochs_type_value if save_n_epochs_type == \"save_every_n_epochs\" else None,\n","        \"save_n_epoch_ratio\": save_n_epochs_type_value if save_n_epochs_type == \"save_n_epoch_ratio\" else None,\n","        \"save_last_n_epochs\": None,\n","        \"save_state\": None,\n","        \"save_last_n_epochs_state\": None,\n","        \"resume\": None,\n","        \"train_batch_size\": train_batch_size,\n","        \"max_token_length\": 225,\n","        \"mem_eff_attn\": False,\n","        \"xformers\": True,\n","        \"max_train_epochs\": num_epochs,\n","        \"max_data_loader_n_workers\": 8,\n","        \"persistent_data_loader_workers\": True,\n","        \"seed\": seed if seed > 0 else None,\n","        \"gradient_checkpointing\": gradient_checkpointing,\n","        \"gradient_accumulation_steps\": gradient_accumulation_steps,\n","        \"mixed_precision\": mixed_precision,\n","        \"clip_skip\": clip_skip if not v2 else None,\n","        \"logging_dir\": logging_dir,\n","        \"log_prefix\": project_name,\n","        \"noise_offset\": noise_offset if noise_offset > 0 else None,\n","        \"lowram\": lowram,\n","    },\n","    \"sample_prompt_arguments\":{\n","        \"sample_every_n_steps\": sample_every_n_type_value if sample_every_n_type == \"sample_every_n_steps\" else None,\n","        \"sample_every_n_epochs\": sample_every_n_type_value if sample_every_n_type == \"sample_every_n_epochs\" else None,\n","        \"sample_sampler\": sampler,\n","    },\n","    \"dreambooth_arguments\":{\n","        \"prior_loss_weight\": 1.0,\n","    },\n","    \"saving_arguments\":{\n","        \"save_model_as\": save_model_as\n","    },\n","}\n","\n","config_path = os.path.join(config_dir, \"config_file.toml\")\n","\n","for key in config:\n","    if isinstance(config[key], dict):\n","        for sub_key in config[key]:\n","            if config[key][sub_key] == \"\":\n","                config[key][sub_key] = None\n","    elif config[key] == \"\":\n","        config[key] = None\n","\n","config_str = toml.dumps(config)\n","\n","with open(config_path, \"w\") as f:\n","    f.write(config_str)\n","\n","print(config_str)"]},{"cell_type":"markdown","metadata":{"id":"mj34CivoOXnG"},"source":["# ‚åõÔ∏è 4. Run"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4aLP0FKV4ziY"},"outputs":[],"source":["#@markdown #‚ñ∂Ô∏è Theo d√µi qu√° tr√¨nh v√† ki·ªÉm so√°t ch·∫•t l∆∞·ª£ng\n","#@markdown *Ki·ªÉm tra sample t·∫°i ```{Output_Path}/sample```*\n","#@markdown <br>*C√≥ th·ªÉ d·ª´ng b·∫•t c·ª© khi n√†o sample th·∫•y ∆∞ng √Ω*\n","\n","os.chdir(repo_dir)\n","!accelerate launch \\\n","  --config_file={accelerate_config} \\\n","  --num_cpu_threads_per_process=1 \\\n","  train_network.py \\\n","  --sample_prompts=/content/LoRA/config/sample_prompt.txt \\\n","  --dataset_config=/content/LoRA/config/dataset_config.toml \\\n","  --config_file=/content/LoRA/config/config_file.toml\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["IPT0DeMD761Z"],"private_outputs":true,"provenance":[{"file_id":"11jjKTtuIcXOc41Dp5wRCYn-qAGGNqpgH","timestamp":1684512352417},{"file_id":"1WtsDJwLd7E-CuscvdD9j_nE74NgHM0tT","timestamp":1678802609727}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}